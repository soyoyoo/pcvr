{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# \n",
    "# Build pCVR using GAP bigquery and Tensorflow DNN library \n",
    "# Used calibration period for training & holdout period for validation\n",
    "# Script can be run on Compute Engine of GCP\n",
    "# The query to extract GA360 features referred to an Auto case by Yiling Liu(yilliu@) \n",
    "# \n",
    "# By JeeWook Kim\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: pip in /usr/local/lib/python2.7/dist-packages (18.0)\n",
      "Requirement already up-to-date: google-api-python-client in /usr/local/lib/python2.7/dist-packages (1.7.4)\n",
      "Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1)\n",
      "Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3)\n",
      "Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0)\n",
      "Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0)\n",
      "Requirement already satisfied, skipping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.10.3)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (0.2.2)\n",
      "Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2)\n",
      "Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (2.0.1)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1<0.5.0,>=0.4.1 in /usr/local/lib/python2.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.4.1->google-api-python-client) (0.4.4)\n",
      "Requirement already up-to-date: gcloud in /usr/local/lib/python2.7/dist-packages (0.18.3)\n",
      "Requirement already satisfied, skipping upgrade: grpc-google-logging-v2<0.9dev,>=0.8.0 in /usr/local/lib/python2.7/dist-packages (from gcloud) (0.8.1)\n",
      "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python2.7/dist-packages (from gcloud) (1.11.0)\n",
      "Requirement already satisfied, skipping upgrade: protobuf!=3.0.0.b2.post1,>=3.0.0b2 in /usr/local/lib/python2.7/dist-packages (from gcloud) (3.6.0)\n",
      "Requirement already satisfied, skipping upgrade: oauth2client>=2.0.1 in /usr/local/lib/python2.7/dist-packages (from gcloud) (2.2.0)\n",
      "Requirement already satisfied, skipping upgrade: googleapis-common-protos in /usr/local/lib/python2.7/dist-packages (from gcloud) (1.5.3)\n",
      "Requirement already satisfied, skipping upgrade: gax-google-pubsub-v1<0.9dev,>=0.8.0 in /usr/local/lib/python2.7/dist-packages (from gcloud) (0.8.3)\n",
      "Requirement already satisfied, skipping upgrade: grpc-google-pubsub-v1<0.9dev,>=0.8.0 in /usr/local/lib/python2.7/dist-packages (from gcloud) (0.8.1)\n",
      "Requirement already satisfied, skipping upgrade: google-gax<0.13dev,>=0.12.3 in /usr/local/lib/python2.7/dist-packages (from gcloud) (0.12.5)\n",
      "Requirement already satisfied, skipping upgrade: gax-google-logging-v2<0.9dev,>=0.8.0 in /usr/local/lib/python2.7/dist-packages (from gcloud) (0.8.3)\n",
      "Requirement already satisfied, skipping upgrade: grpcio>=1.0rc1 in /usr/local/lib/python2.7/dist-packages (from gcloud) (1.13.0)\n",
      "Requirement already satisfied, skipping upgrade: httplib2>=0.9.1 in /usr/local/lib/python2.7/dist-packages (from gcloud) (0.10.3)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python2.7/dist-packages (from protobuf!=3.0.0.b2.post1,>=3.0.0b2->gcloud) (39.1.0)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.7 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=2.0.1->gcloud) (0.4.4)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.0.5 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=2.0.1->gcloud) (0.2.2)\n",
      "Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=2.0.1->gcloud) (3.4.2)\n",
      "Requirement already satisfied, skipping upgrade: ply==3.8 in /usr/local/lib/python2.7/dist-packages (from google-gax<0.13dev,>=0.12.3->gcloud) (3.8)\n",
      "Requirement already satisfied, skipping upgrade: future>=0.15.2 in /usr/local/lib/python2.7/dist-packages (from google-gax<0.13dev,>=0.12.3->gcloud) (0.16.0)\n",
      "Requirement already satisfied, skipping upgrade: futures>=2.2.0 in /usr/local/lib/python2.7/dist-packages (from grpcio>=1.0rc1->gcloud) (3.2.0)\n",
      "Requirement already satisfied, skipping upgrade: enum34>=1.0.4 in /usr/local/lib/python2.7/dist-packages (from grpcio>=1.0rc1->gcloud) (1.1.6)\n",
      "Requirement already satisfied: tensorflow in /usr/local/lib/python2.7/dist-packages (1.9.0)\n",
      "Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow) (2.0.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python2.7/dist-packages (from tensorflow) (1.13.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python2.7/dist-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: tensorboard<1.10.0,>=1.9.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow) (1.9.0)\n",
      "Requirement already satisfied: backports.weakref>=1.0rc1 in /usr/local/lib/python2.7/dist-packages (from tensorflow) (1.0.post1)\n",
      "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python2.7/dist-packages (from tensorflow) (0.3.0)\n",
      "Requirement already satisfied: wheel in /usr/local/lib/python2.7/dist-packages (from tensorflow) (0.31.1)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow) (1.11.0)\n",
      "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: enum34>=1.1.6 in /usr/local/lib/python2.7/dist-packages (from tensorflow) (1.1.6)\n",
      "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow) (0.7.1)\n",
      "Requirement already satisfied: setuptools<=39.1.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow) (39.1.0)\n",
      "Requirement already satisfied: funcsigs>=1; python_version < \"3.3\" in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0->tensorflow) (1.0.2)\n",
      "Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0->tensorflow) (4.2.0)\n",
      "Requirement already satisfied: futures>=2.2.0 in /usr/local/lib/python2.7/dist-packages (from grpcio>=1.8.6->tensorflow) (3.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python2.7/dist-packages (from tensorboard<1.10.0,>=1.9.0->tensorflow) (2.6.11)\n",
      "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python2.7/dist-packages (from tensorboard<1.10.0,>=1.9.0->tensorflow) (0.14.1)\n",
      "Collecting tensorflow==1.9.0\n",
      "  Using cached https://files.pythonhosted.org/packages/37/ff/97d4542f805ae25bf4b65b6263515584c78bd9a6111ed78ea971eff2946a/tensorflow-1.9.0-cp27-cp27mu-manylinux1_x86_64.whl\n",
      "Collecting mock>=2.0.0 (from tensorflow==1.9.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/e6/35/f187bdf23be87092bd0f1200d43d23076cee4d0dec109f195173fd3ebc79/mock-2.0.0-py2.py3-none-any.whl\n",
      "Collecting grpcio>=1.8.6 (from tensorflow==1.9.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/fa/53/685b9d68e5734cf8e2d13b2d4d29e6cede94714b665019a5627a623b3e21/grpcio-1.13.0-cp27-cp27mu-manylinux1_x86_64.whl\n",
      "Collecting termcolor>=1.1.0 (from tensorflow==1.9.0)\n",
      "Collecting numpy>=1.13.3 (from tensorflow==1.9.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/85/51/ba4564ded90e093dbb6adfc3e21f99ae953d9ad56477e1b0d4a93bacf7d3/numpy-1.15.0-cp27-cp27mu-manylinux1_x86_64.whl\n",
      "Collecting tensorboard<1.10.0,>=1.9.0 (from tensorflow==1.9.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/d5/98/e2e9d5afbc86cef0b2dd0f4ab791519b9bd305ea207e1e5c2f9a9f2f6da6/tensorboard-1.9.0-py2-none-any.whl\n",
      "Collecting backports.weakref>=1.0rc1 (from tensorflow==1.9.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/88/ec/f598b633c3d5ffe267aaada57d961c94fdfa183c5c3ebda2b6d151943db6/backports.weakref-1.0.post1-py2.py3-none-any.whl\n",
      "Collecting absl-py>=0.1.6 (from tensorflow==1.9.0)\n",
      "Collecting wheel (from tensorflow==1.9.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/81/30/e935244ca6165187ae8be876b6316ae201b71485538ffac1d718843025a9/wheel-0.31.1-py2.py3-none-any.whl\n",
      "Collecting six>=1.10.0 (from tensorflow==1.9.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/67/4b/141a581104b1f6397bfa78ac9d43d8ad29a7ca43ea90a2d863fe3056e86a/six-1.11.0-py2.py3-none-any.whl\n",
      "Collecting gast>=0.2.0 (from tensorflow==1.9.0)\n",
      "Collecting enum34>=1.1.6 (from tensorflow==1.9.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/c5/db/e56e6b4bbac7c4a06de1c50de6fe1ef3810018ae11732a50f15f62c7d050/enum34-1.1.6-py2-none-any.whl\n",
      "Collecting protobuf>=3.4.0 (from tensorflow==1.9.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/27/e7/bf96130ebe633b08a3913da4bb25e50dac5779f1f68e51c99485423f7443/protobuf-3.6.0-cp27-cp27mu-manylinux1_x86_64.whl\n",
      "Collecting astor>=0.6.0 (from tensorflow==1.9.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/35/6b/11530768cac581a12952a2aad00e1526b89d242d0b9f59534ef6e6a1752f/astor-0.7.1-py2.py3-none-any.whl\n",
      "Collecting setuptools<=39.1.0 (from tensorflow==1.9.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/8c/10/79282747f9169f21c053c562a0baa21815a8c7879be97abd930dbcf862e8/setuptools-39.1.0-py2.py3-none-any.whl\n",
      "Collecting funcsigs>=1; python_version < \"3.3\" (from mock>=2.0.0->tensorflow==1.9.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/69/cb/f5be453359271714c01b9bd06126eaf2e368f1fddfff30818754b5ac2328/funcsigs-1.0.2-py2.py3-none-any.whl\n",
      "Collecting pbr>=0.11 (from mock>=2.0.0->tensorflow==1.9.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/69/1c/98cba002ed975a91a0294863d9c774cc0ebe38e05bbb65e83314550b1677/pbr-4.2.0-py2.py3-none-any.whl\n",
      "Collecting futures>=2.2.0 (from grpcio>=1.8.6->tensorflow==1.9.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/2d/99/b2c4e9d5a30f6471e410a146232b4118e697fa3ffc06d6a65efde84debd0/futures-3.2.0-py2-none-any.whl\n",
      "Collecting markdown>=2.6.8 (from tensorboard<1.10.0,>=1.9.0->tensorflow==1.9.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/6d/7d/488b90f470b96531a3f5788cf12a93332f543dbab13c423a5e7ce96a0493/Markdown-2.6.11-py2.py3-none-any.whl\n",
      "Collecting werkzeug>=0.11.10 (from tensorboard<1.10.0,>=1.9.0->tensorflow==1.9.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/20/c4/12e3e56473e52375aa29c4764e70d1b8f3efa6682bef8d0aae04fe335243/Werkzeug-0.14.1-py2.py3-none-any.whl\n",
      "Installing collected packages: six, funcsigs, pbr, mock, futures, enum34, grpcio, termcolor, numpy, wheel, setuptools, protobuf, markdown, werkzeug, tensorboard, backports.weakref, absl-py, gast, astor, tensorflow\n",
      "Successfully installed absl-py-0.3.0 astor-0.7.1 backports.weakref-1.0.post1 enum34-1.1.6 funcsigs-1.0.2 futures-3.2.0 gast-0.2.0 grpcio-1.13.0 markdown-2.6.11 mock-2.0.0 numpy-1.15.0 pbr-4.2.0 protobuf-3.6.0 setuptools-39.1.0 six-1.11.0 tensorboard-1.9.0 tensorflow-1.9.0 termcolor-1.1.0 werkzeug-0.14.1 wheel-0.31.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "google-cloud 0.27.0 has requirement google-cloud-core<0.27dev,>=0.26.0, but you'll have google-cloud-core 0.27.1 which is incompatible.\n",
      "google-cloud 0.27.0 has requirement google-cloud-storage<1.4dev,>=1.3.0, but you'll have google-cloud-storage 1.4.0 which is incompatible.\n",
      "google-cloud-vision 0.26.0 has requirement google-cloud-core<0.27dev,>=0.26.0, but you'll have google-cloud-core 0.27.1 which is incompatible.\n",
      "google-cloud-vision 0.26.0 has requirement google-gax<0.16dev,>=0.15.13, but you'll have google-gax 0.12.5 which is incompatible.\n",
      "google-cloud-logging 1.2.0 has requirement google-cloud-core<0.27dev,>=0.26.0, but you'll have google-cloud-core 0.27.1 which is incompatible.\n",
      "google-cloud-speech 0.28.0 has requirement google-cloud-core<0.27dev,>=0.26.0, but you'll have google-cloud-core 0.27.1 which is incompatible.\n",
      "google-cloud-speech 0.28.0 has requirement google-gax<0.16dev,>=0.15.13, but you'll have google-gax 0.12.5 which is incompatible.\n",
      "google-cloud-videointelligence 0.25.0 has requirement google-gax<0.16dev,>=0.15.12, but you'll have google-gax 0.12.5 which is incompatible.\n",
      "google-cloud-spanner 0.26.0 has requirement google-cloud-core<0.27dev,>=0.26.0, but you'll have google-cloud-core 0.27.1 which is incompatible.\n",
      "google-cloud-storage 1.4.0 has requirement requests>=2.18.0, but you'll have requests 2.9.1 which is incompatible.\n",
      "datalab 1.1.0 has requirement futures==3.0.5, but you'll have futures 3.2.0 which is incompatible.\n",
      "datalab 1.1.0 has requirement google-api-python-client==1.6.2, but you'll have google-api-python-client 1.7.4 which is incompatible.\n",
      "datalab 1.1.0 has requirement google_auth_httplib2==0.0.2, but you'll have google-auth-httplib2 0.0.3 which is incompatible.\n",
      "datalab 1.1.0 has requirement six==1.10.0, but you'll have six 1.11.0 which is incompatible.\n",
      "gapic-google-cloud-logging-v2 0.91.3 has requirement google-gax<0.16dev,>=0.15.7, but you'll have google-gax 0.12.5 which is incompatible.\n",
      "gapic-google-cloud-datastore-v1 0.15.3 has requirement google-gax<0.16dev,>=0.15.8, but you'll have google-gax 0.12.5 which is incompatible.\n",
      "google-cloud-dataflow 2.0.0 has requirement google-cloud-bigquery<0.24.0,>=0.23.0, but you'll have google-cloud-bigquery 0.26.0 which is incompatible.\n",
      "google-cloud-dataflow 2.0.0 has requirement httplib2<0.10,>=0.8, but you'll have httplib2 0.10.3 which is incompatible.\n",
      "google-cloud-dataflow 2.0.0 has requirement proto-google-cloud-datastore-v1==0.90.0, but you'll have proto-google-cloud-datastore-v1 0.90.4 which is incompatible.\n",
      "google-cloud-dataflow 2.0.0 has requirement protobuf==3.2.0, but you'll have protobuf 3.6.0 which is incompatible.\n",
      "google-cloud-dataflow 2.0.0 has requirement pyyaml<4.0.0,>=3.12, but you'll have pyyaml 3.11 which is incompatible.\n",
      "google-cloud-core 0.27.1 has requirement requests<3.0.0dev,>=2.18.0, but you'll have requests 2.9.1 which is incompatible.\n",
      "gapic-google-cloud-spanner-v1 0.15.3 has requirement google-gax<0.16dev,>=0.15.7, but you'll have google-gax 0.12.5 which is incompatible.\n",
      "google-cloud-bigquery 0.26.0 has requirement google-cloud-core<0.27dev,>=0.26.0, but you'll have google-cloud-core 0.27.1 which is incompatible.\n",
      "gapic-google-cloud-spanner-admin-database-v1 0.15.3 has requirement google-gax<0.16dev,>=0.15.7, but you'll have google-gax 0.12.5 which is incompatible.\n",
      "google-cloud-pubsub 0.27.0 has requirement google-cloud-core<0.27dev,>=0.26.0, but you'll have google-cloud-core 0.27.1 which is incompatible.\n",
      "airflow 1.8.0 has requirement funcsigs==1.0.0, but you'll have funcsigs 1.0.2 which is incompatible.\n",
      "airflow 1.8.0 has requirement future<0.16,>=0.15.0, but you'll have future 0.16.0 which is incompatible.\n",
      "gapic-google-cloud-pubsub-v1 0.15.4 has requirement google-gax<0.16dev,>=0.15.7, but you'll have google-gax 0.12.5 which is incompatible.\n",
      "google-cloud-language 0.27.0 has requirement google-cloud-core<0.27dev,>=0.26.0, but you'll have google-cloud-core 0.27.1 which is incompatible.\n",
      "google-cloud-language 0.27.0 has requirement google-gax<0.16dev,>=0.15.13, but you'll have google-gax 0.12.5 which is incompatible.\n",
      "google-cloud-runtimeconfig 0.26.0 has requirement google-cloud-core<0.27dev,>=0.26.0, but you'll have google-cloud-core 0.27.1 which is incompatible.\n",
      "gapic-google-cloud-error-reporting-v1beta1 0.15.3 has requirement google-gax<0.16dev,>=0.15.7, but you'll have google-gax 0.12.5 which is incompatible.\n",
      "gapic-google-cloud-spanner-admin-instance-v1 0.15.3 has requirement google-gax<0.16dev,>=0.15.7, but you'll have google-gax 0.12.5 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pip install --upgrade pip\n",
    "pip install --upgrade google-api-python-client\n",
    "pip install --upgrade gcloud\n",
    "pip install tensorflow\n",
    "pip install --ignore-installed --upgrade tensorflow==1.9.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/scipy/ndimage/measurements.py:36: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import _ni_label\n",
      "/usr/local/lib/python2.7/dist-packages/scipy/ndimage/measurements.py:36: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  from . import _ni_label\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Prepare dataset using GA360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9.0\n",
      "# training_set_data\n",
      "[[6.4 2.8 5.6 2.2]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.1 3.7 1.5 0.4]]\n",
      "# training_set_target\n",
      "[2 1 2 0 0 0 0 2 1 0]\n",
      "# test_set_data\n",
      "[[5.9 3.  4.2 1.5]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [6.7 2.5 5.8 1.8]]\n",
      "# test_set_target\n",
      "[1 2 0 1 1 1 0 2 1 2]\n",
      "# today: 20180802\n",
      "# begin_date: 20160801\n",
      "# end_date: 20170801\n",
      "# calibration_end_date: 20170201\n",
      "# BigQuery SQL - train data\n",
      " \n",
      "          WITH ga_raw AS (\n",
      "          SELECT\n",
      "            date,\n",
      "            fullVisitorId,\n",
      "            channelGrouping,\n",
      "            socialEngagementType,\n",
      "            visitId,\n",
      "            visitNumber,\n",
      "            trafficSource.source,\n",
      "            trafficSource.medium,\n",
      "            device.deviceCategory,\n",
      "            device.browser,\n",
      "            hits.hitNumber,\n",
      "            hits.page.pagePath as pagePath,\n",
      "            hits.type as type,\n",
      "            hits.eventInfo.eventCategory as eventCategory,\n",
      "            hits.eventInfo.eventAction as eventAction,\n",
      "            hits.eventInfo.eventLabel as eventLabel,\n",
      "            TIMESTAMP_SECONDS(visitStartTime) AS sessionStartTtime, \n",
      "            TIMESTAMP_ADD(TIMESTAMP_SECONDS(visitStartTime), INTERVAL hits.time MILLISECOND) AS hitTime,\n",
      "            CASE WHEN hits.hour IN (5,6,7,8,9,10) THEN 1 ELSE 0 END AS morningVisit,\n",
      "            CASE WHEN hits.hour IN (11,12,13,14,15,16) THEN 1 ELSE 0 END AS dayVisit,\n",
      "            CASE WHEN hits.hour IN (17,18,19,20,21,22) THEN 1 ELSE 0 END AS eveningVisit,\n",
      "            totals.timeOnSite AS timeOnSite,\n",
      "            totals.bounces AS bounceNumber,\n",
      "            totals.timeOnScreen\tAS timeOnScreen,\n",
      "            totals.transactions AS transactions,\n",
      "            IF(REGEXP_CONTAINS(trafficSource.source , 'google') AND REGEXP_CONTAINS(trafficSource.medium , 'cpc'), 1, 0) AS fromPaidSearch,\n",
      "            IF(REGEXP_CONTAINS(trafficSource.source , 'google') AND REGEXP_CONTAINS(trafficSource.medium , 'organic'), 1, 0) AS fromOrganicSearch\n",
      "          FROM `bigquery-public-data.google_analytics_sample.ga_sessions_*`, unnest(hits) as hits\n",
      "          WHERE\n",
      "           (_TABLE_SUFFIX >= '20160801' AND _TABLE_SUFFIX <= '20170201') ),\n",
      "       \n",
      "        session AS ( -- aggregate hit level to session level\n",
      "          SELECT fullVisitorId, visitId,\n",
      "            SUM(if (timeOnSite is null, 0, timeOnSite)) AS timeOnSite,\n",
      "            SUM(if (bounceNumber is null, 0, bounceNumber)) AS bounceNumber,\n",
      "            SUM( dayVisit ) AS dayVisit,\n",
      "            SUM( eveningVisit ) AS eveningVisit ,\n",
      "            SUM( morningVisit ) AS morningVisit ,\n",
      "            ANY_VALUE(visitNumber) as visitNumber,\n",
      "\n",
      "            SUM(if( type = 'PAGE', 1, 0)) as totalPageViews, \n",
      "            SUM(if( type = 'EVENT', 1, 0)) as totalEvents, \n",
      "\n",
      "            SUM(if(pagePath LIKE '%/apparel%', 1, 0)) as apparelViews,\n",
      "            SUM(if(pagePath LIKE '%/bags%', 1, 0)) as bagsViews,\n",
      "            SUM(if(pagePath LIKE '%/drinkware%', 1, 0)) as drinkwareViews,\n",
      "            SUM(if(pagePath LIKE '%/accessories%', 1, 0)) as accessoriesViews,\n",
      "            SUM(if(pagePath LIKE '%/office%', 1, 0)) as officeViews,\n",
      "\n",
      "            IF(SUM(fromPaidSearch) != 0, 1, 0) AS  fromPaidSearch,\n",
      "            IF(SUM(fromOrganicSearch) != 0, 1, 0) AS  fromOrganicSearch,\n",
      "\n",
      "            IF(SUM(transactions) is null, False, True) AS hasConverted,\n",
      "\n",
      "            COUNT(*) as totalInteractions    \n",
      "          FROM ga_raw\n",
      "          GROUP BY fullVisitorId , visitId ),\n",
      "  \n",
      "       ml_dataset AS ( -- aggregate seesion level data to user level\n",
      "\n",
      "          SELECT \n",
      "            fullVisitorId, \n",
      "            MAX(visitNumber) as totalSessions,\n",
      "            SUM(totalPageViews) as totalPageViews, \n",
      "            SUM(totalInteractions) as totalInteractions, \n",
      "\n",
      "            SUM(timeOnSite) AS timeOnSite,\n",
      "            SUM(bounceNumber) AS bounceNumber,\n",
      "            SUM( dayVisit ) AS dayVisit,\n",
      "            SUM( eveningVisit ) AS eveningVisit ,\n",
      "            SUM( morningVisit ) AS morningVisit ,\n",
      "\n",
      "            SUM(totalEvents) as totalEvents, \n",
      "\n",
      "            SUM(apparelViews) as apparelViews,\n",
      "            SUM(bagsViews) as bagsViews,\n",
      "            SUM(drinkwareViews)  as drinkwareViews,\n",
      "            SUM(accessoriesViews) as accessoriesViews,\n",
      "            SUM(officeViews) as officeViews,\n",
      "\n",
      "            SUM(fromPaidSearch) AS fromPaidSearch,\n",
      "            SUM(fromOrganicSearch) AS fromOrganicSearch,\n",
      "            ANY_VALUE(hasConverted) AS hasConverted\n",
      "\n",
      "          FROM session\n",
      "          GROUP BY fullVisitorId)\n",
      "\n",
      "        select * from ml_dataset; \n",
      "\n",
      "# BigQuery SQL - test data\n",
      " \n",
      "         WITH ga_raw AS (\n",
      "          SELECT\n",
      "            date,\n",
      "            fullVisitorId,\n",
      "            channelGrouping,\n",
      "            socialEngagementType,\n",
      "            visitId,\n",
      "            visitNumber,\n",
      "            trafficSource.source,\n",
      "            trafficSource.medium,\n",
      "            device.deviceCategory,\n",
      "            device.browser,\n",
      "            hits.hitNumber,\n",
      "            hits.page.pagePath as pagePath,\n",
      "            hits.type as type,\n",
      "            hits.eventInfo.eventCategory as eventCategory,\n",
      "            hits.eventInfo.eventAction as eventAction,\n",
      "            hits.eventInfo.eventLabel as eventLabel,\n",
      "            TIMESTAMP_SECONDS(visitStartTime) AS sessionStartTtime, \n",
      "            TIMESTAMP_ADD(TIMESTAMP_SECONDS(visitStartTime), INTERVAL hits.time MILLISECOND) AS hitTime,\n",
      "            CASE WHEN hits.hour IN (5,6,7,8,9,10) THEN 1 ELSE 0 END AS morningVisit,\n",
      "            CASE WHEN hits.hour IN (11,12,13,14,15,16) THEN 1 ELSE 0 END AS dayVisit,\n",
      "            CASE WHEN hits.hour IN (17,18,19,20,21,22) THEN 1 ELSE 0 END AS eveningVisit,\n",
      "            totals.timeOnSite AS timeOnSite,\n",
      "            totals.bounces AS bounceNumber,\n",
      "            totals.timeOnScreen\tAS timeOnScreen,\n",
      "            totals.transactions AS transactions,\n",
      "            IF(REGEXP_CONTAINS(trafficSource.source , 'google') AND REGEXP_CONTAINS(trafficSource.medium , 'cpc'), 1, 0) AS fromPaidSearch,\n",
      "            IF(REGEXP_CONTAINS(trafficSource.source , 'google') AND REGEXP_CONTAINS(trafficSource.medium , 'organic'), 1, 0) AS fromOrganicSearch\n",
      "          FROM `bigquery-public-data.google_analytics_sample.ga_sessions_*`, unnest(hits) as hits\n",
      "          WHERE\n",
      "           (_TABLE_SUFFIX > '20170201' AND _TABLE_SUFFIX <= '20170801') ),\n",
      "       \n",
      "        session AS ( -- aggregate hit level to session level\n",
      "          SELECT fullVisitorId, visitId,\n",
      "            SUM(if (timeOnSite is null, 0, timeOnSite)) AS timeOnSite,\n",
      "            SUM(if (bounceNumber is null, 0, bounceNumber)) AS bounceNumber,\n",
      "            SUM( dayVisit ) AS dayVisit,\n",
      "            SUM( eveningVisit ) AS eveningVisit ,\n",
      "            SUM( morningVisit ) AS morningVisit ,\n",
      "            ANY_VALUE(visitNumber) as visitNumber,\n",
      "\n",
      "            SUM(if( type = 'PAGE', 1, 0)) as totalPageViews, \n",
      "            SUM(if( type = 'EVENT', 1, 0)) as totalEvents, \n",
      "\n",
      "            SUM(if(pagePath LIKE '%/apparel%', 1, 0)) as apparelViews,\n",
      "            SUM(if(pagePath LIKE '%/bags%', 1, 0)) as bagsViews,\n",
      "            SUM(if(pagePath LIKE '%/drinkware%', 1, 0)) as drinkwareViews,\n",
      "            SUM(if(pagePath LIKE '%/accessories%', 1, 0)) as accessoriesViews,\n",
      "            SUM(if(pagePath LIKE '%/office%', 1, 0)) as officeViews,\n",
      "\n",
      "            IF(SUM(fromPaidSearch) != 0, 1, 0) AS  fromPaidSearch,\n",
      "            IF(SUM(fromOrganicSearch) != 0, 1, 0) AS  fromOrganicSearch,\n",
      "\n",
      "            IF(SUM(transactions) is null, False, True) AS hasConverted,\n",
      "\n",
      "            COUNT(*) as totalInteractions    \n",
      "          FROM ga_raw\n",
      "          GROUP BY fullVisitorId , visitId ),\n",
      "  \n",
      "       ml_dataset AS ( -- aggregate seesion level data to user level\n",
      "\n",
      "          SELECT \n",
      "            fullVisitorId, \n",
      "            MAX(visitNumber) as totalSessions,\n",
      "            SUM(totalPageViews) as totalPageViews, \n",
      "            SUM(totalInteractions) as totalInteractions, \n",
      "\n",
      "            SUM(timeOnSite) AS timeOnSite,\n",
      "            SUM(bounceNumber) AS bounceNumber,\n",
      "            SUM( dayVisit ) AS dayVisit,\n",
      "            SUM( eveningVisit ) AS eveningVisit ,\n",
      "            SUM( morningVisit ) AS morningVisit ,\n",
      "\n",
      "            SUM(totalEvents) as totalEvents, \n",
      "\n",
      "            SUM(apparelViews) as apparelViews,\n",
      "            SUM(bagsViews) as bagsViews,\n",
      "            SUM(drinkwareViews)  as drinkwareViews,\n",
      "            SUM(accessoriesViews) as accessoriesViews,\n",
      "            SUM(officeViews) as officeViews,\n",
      "\n",
      "            SUM(fromPaidSearch) AS fromPaidSearch,\n",
      "            SUM(fromOrganicSearch) AS fromOrganicSearch,\n",
      "            ANY_VALUE(hasConverted) AS hasConverted\n",
      "\n",
      "          FROM session\n",
      "          GROUP BY fullVisitorId)\n",
      "\n",
      "        select * from ml_dataset; \n",
      "\n",
      "# query_data # of converted users 2850\n",
      "              fullVisitorId  totalSessions  totalPageViews  totalInteractions  \\\n",
      "224070  0213071560453106423              1               6                  6   \n",
      "233093  9840650149470197060              1               7                  7   \n",
      "235069  6539518527897980356              1               8                  8   \n",
      "237059  4272803504302903779              1               8                  8   \n",
      "237586  7651728310132014868              1               8                  8   \n",
      "238028  8951208689934718226              1               8                  8   \n",
      "238350  3631468795643448744              1               9                  9   \n",
      "239914   498824129707847807              1               9                  9   \n",
      "239964  6176979987115887287              1               9                  9   \n",
      "240642  6321103113579236784              2               9                  9   \n",
      "241427  7806543448896890229              1               9                  9   \n",
      "242293  8575483505094728323              1              10                 10   \n",
      "242428  0665007615083266355              1               8                 10   \n",
      "242431  4112758013155736648              1              10                 10   \n",
      "242643  7670621252820310471              1              10                 10   \n",
      "243107  3575272597943168955              1               9                 10   \n",
      "243282  9090173644074015025              1              10                 10   \n",
      "243431  8264857327019911007              1              10                 10   \n",
      "243800  7999476853921506700              1              10                 10   \n",
      "244177  7830344002776874199              1              10                 10   \n",
      "\n",
      "        timeOnSite  bounceNumber  dayVisit  eveningVisit  morningVisit  \\\n",
      "224070        1962             0         6             0             0   \n",
      "233093        1407             0         0             7             0   \n",
      "235069        2464             0         8             0             0   \n",
      "237059        1144             0         0             8             0   \n",
      "237586       11624             0         0             8             0   \n",
      "238028        2488             0         8             0             0   \n",
      "238350        2655             0         9             0             0   \n",
      "239914        1881             0         9             0             0   \n",
      "239964        5643             0         9             0             0   \n",
      "240642        2043             0         0             9             0   \n",
      "241427        2673             0         0             0             0   \n",
      "242293       15350             0        10             0             0   \n",
      "242428        2470             0         0             0             0   \n",
      "242431        2870             0        10             0             0   \n",
      "242643        1410             0        10             0             0   \n",
      "243107        2030             0        10             0             0   \n",
      "243282        1730             0         0            10             0   \n",
      "243431        3200             0        10             0             0   \n",
      "243800        5830             0        10             0             0   \n",
      "244177        4180             0        10             0             0   \n",
      "\n",
      "        totalEvents  apparelViews  bagsViews  drinkwareViews  \\\n",
      "224070            0             0          0               0   \n",
      "233093            0             0          0               0   \n",
      "235069            0             0          0               0   \n",
      "237059            0             0          0               0   \n",
      "237586            0             0          0               0   \n",
      "238028            0             0          0               0   \n",
      "238350            0             0          0               0   \n",
      "239914            0             0          0               0   \n",
      "239964            0             0          0               1   \n",
      "240642            0             1          0               0   \n",
      "241427            0             0          0               0   \n",
      "242293            0             0          0               0   \n",
      "242428            2             0          0               0   \n",
      "242431            0             2          0               0   \n",
      "242643            0             1          0               0   \n",
      "243107            1             0          0               0   \n",
      "243282            0             0          0               0   \n",
      "243431            0             0          0               0   \n",
      "243800            0             0          0               0   \n",
      "244177            0             0          0               0   \n",
      "\n",
      "        accessoriesViews  officeViews  fromPaidSearch  fromOrganicSearch  \\\n",
      "224070                 0            0               0                  0   \n",
      "233093                 0            0               0                  0   \n",
      "235069                 0            0               0                  0   \n",
      "237059                 0            0               0                  0   \n",
      "237586                 0            0               0                  0   \n",
      "238028                 0            0               0                  0   \n",
      "238350                 0            0               0                  1   \n",
      "239914                 0            0               0                  0   \n",
      "239964                 0            0               0                  0   \n",
      "240642                 0            0               0                  0   \n",
      "241427                 0            0               0                  0   \n",
      "242293                 0            0               1                  0   \n",
      "242428                 0            0               0                  1   \n",
      "242431                 0            0               0                  0   \n",
      "242643                 0            0               0                  0   \n",
      "243107                 0            0               0                  0   \n",
      "243282                 0            0               0                  0   \n",
      "243431                 0            0               0                  0   \n",
      "243800                 0            0               0                  0   \n",
      "244177                 0            0               0                  0   \n",
      "\n",
      "       hasConverted  \n",
      "224070         True  \n",
      "233093         True  \n",
      "235069         True  \n",
      "237059         True  \n",
      "237586         True  \n",
      "238028         True  \n",
      "238350         True  \n",
      "239914         True  \n",
      "239964         True  \n",
      "240642         True  \n",
      "241427         True  \n",
      "242293         True  \n",
      "242428         True  \n",
      "242431         True  \n",
      "242643         True  \n",
      "243107         True  \n",
      "243282         True  \n",
      "243431         True  \n",
      "243800         True  \n",
      "244177         True  \n",
      "# query_data # of not converted users 403413\n",
      "          fullVisitorId  totalSessions  totalPageViews  totalInteractions  \\\n",
      "0   6453870986532490896              5             192                256   \n",
      "1      1181612171924800              1               1                  1   \n",
      "2   4955958620185049767              1               1                  1   \n",
      "3   0149802282876784178              1               1                  1   \n",
      "4   5750416220831639083              1               1                  1   \n",
      "5   4883523561655881302              1               1                  1   \n",
      "6   5967105313126642513              1               1                  1   \n",
      "7   5132448259027648000              1               1                  1   \n",
      "8   8034724617560128671              1               1                  1   \n",
      "9   0562220554109675030              1               1                  1   \n",
      "10  1043182092413874954              1               1                  1   \n",
      "11     2973066524932295              1               1                  1   \n",
      "12  2709492856782258739              1               1                  1   \n",
      "13  2981305942824697932              1               1                  1   \n",
      "14  7517476525607174470              1               1                  1   \n",
      "15  1254835954780532220              1               1                  1   \n",
      "16  3337834572458050421              1               1                  1   \n",
      "17  8611047940961152432              1               1                  1   \n",
      "18  1315496083867002971              1               1                  1   \n",
      "19  7639242350407457183              1               1                  1   \n",
      "\n",
      "    timeOnSite  bounceNumber  dayVisit  eveningVisit  morningVisit  \\\n",
      "0       226473             0       220            36             0   \n",
      "1            0             1         0             1             0   \n",
      "2            0             1         0             1             0   \n",
      "3            0             1         0             1             0   \n",
      "4            0             1         0             0             0   \n",
      "5            0             1         0             1             0   \n",
      "6            0             1         1             0             0   \n",
      "7            0             1         1             0             0   \n",
      "8            0             1         0             0             0   \n",
      "9            0             1         0             0             0   \n",
      "10           0             1         1             0             0   \n",
      "11           0             1         1             0             0   \n",
      "12           0             1         1             0             0   \n",
      "13           0             1         1             0             0   \n",
      "14           0             1         0             0             0   \n",
      "15           0             1         0             1             0   \n",
      "16           0             1         0             0             0   \n",
      "17           0             1         0             0             0   \n",
      "18           0             1         0             0             0   \n",
      "19           0             1         0             0             0   \n",
      "\n",
      "    totalEvents  apparelViews  bagsViews  drinkwareViews  accessoriesViews  \\\n",
      "0            64            25          6               3                26   \n",
      "1             0             0          0               0                 0   \n",
      "2             0             0          0               0                 0   \n",
      "3             0             0          0               0                 0   \n",
      "4             0             0          0               0                 0   \n",
      "5             0             0          0               0                 0   \n",
      "6             0             0          0               0                 0   \n",
      "7             0             1          0               0                 0   \n",
      "8             0             0          0               0                 0   \n",
      "9             0             0          0               0                 0   \n",
      "10            0             0          0               0                 0   \n",
      "11            0             0          0               0                 0   \n",
      "12            0             0          0               0                 0   \n",
      "13            0             0          0               0                 0   \n",
      "14            0             1          0               0                 0   \n",
      "15            0             0          0               0                 0   \n",
      "16            0             0          0               0                 0   \n",
      "17            0             0          0               0                 0   \n",
      "18            0             0          0               0                 0   \n",
      "19            0             0          0               0                 0   \n",
      "\n",
      "    officeViews  fromPaidSearch  fromOrganicSearch hasConverted  \n",
      "0            43               1                  2        False  \n",
      "1             0               0                  0        False  \n",
      "2             0               0                  0        False  \n",
      "3             0               0                  0        False  \n",
      "4             0               0                  0        False  \n",
      "5             0               0                  1        False  \n",
      "6             0               0                  0        False  \n",
      "7             0               0                  1        False  \n",
      "8             0               0                  0        False  \n",
      "9             0               0                  1        False  \n",
      "10            0               0                  0        False  \n",
      "11            0               0                  0        False  \n",
      "12            0               0                  0        False  \n",
      "13            0               0                  0        False  \n",
      "14            0               0                  1        False  \n",
      "15            0               0                  0        False  \n",
      "16            0               0                  0        False  \n",
      "17            0               0                  1        False  \n",
      "18            0               0                  1        False  \n",
      "19            0               0                  0        False  \n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fba33900190>, '_evaluation_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_device_fn': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/tmp/pcvr_model', '_train_distribute': None, '_save_summary_steps': 100}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/pcvr_model/model.ckpt-2000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into /tmp/pcvr_model/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.00017871844, step = 2001\n",
      "INFO:tensorflow:global_step/sec: 334.84\n",
      "INFO:tensorflow:loss = 0.035263255, step = 2101 (0.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 399.208\n",
      "INFO:tensorflow:loss = 0.033679727, step = 2201 (0.251 sec)\n",
      "INFO:tensorflow:global_step/sec: 438.375\n",
      "INFO:tensorflow:loss = 0.038329277, step = 2301 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 375.34\n",
      "INFO:tensorflow:loss = 0.03671808, step = 2401 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 458.283\n",
      "INFO:tensorflow:loss = 0.004047415, step = 2501 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 411.277\n",
      "INFO:tensorflow:loss = 0.005585036, step = 2601 (0.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 402.436\n",
      "INFO:tensorflow:loss = 0.0021458433, step = 2701 (0.249 sec)\n",
      "INFO:tensorflow:global_step/sec: 424.673\n",
      "INFO:tensorflow:loss = 5.2619554e-05, step = 2801 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 421.26\n",
      "INFO:tensorflow:loss = 6.589329e-07, step = 2901 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 436.821\n",
      "INFO:tensorflow:loss = 149.09523, step = 3001 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.354\n",
      "INFO:tensorflow:loss = 116.17164, step = 3101 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 449.584\n",
      "INFO:tensorflow:loss = 8.25694, step = 3201 (0.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 438.689\n",
      "INFO:tensorflow:loss = 2.1356707e-05, step = 3301 (0.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 269.954\n",
      "INFO:tensorflow:loss = 2.3024768e-05, step = 3401 (0.370 sec)\n",
      "INFO:tensorflow:global_step/sec: 403.744\n",
      "INFO:tensorflow:loss = 2.2066939e-05, step = 3501 (0.248 sec)\n",
      "INFO:tensorflow:global_step/sec: 433.065\n",
      "INFO:tensorflow:loss = 2.1780781e-05, step = 3601 (0.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 429.376\n",
      "INFO:tensorflow:loss = 0.85414475, step = 3701 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 411.951\n",
      "INFO:tensorflow:loss = 0.7302746, step = 3801 (0.244 sec)\n",
      "INFO:tensorflow:global_step/sec: 416.594\n",
      "INFO:tensorflow:loss = 1.5669622, step = 3901 (0.239 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4000 into /tmp/pcvr_model/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 3.296117.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-08-02-17:08:03\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/pcvr_model/model.ckpt-4000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-08-02-17:08:10\n",
      "INFO:tensorflow:Saving dict for global step 4000: accuracy = 0.9908754, accuracy_baseline = 0.9908754, auc = 0.8712375, auc_precision_recall = 0.037286542, average_loss = 0.047053628, global_step = 4000, label/mean = 0.009124599, loss = 6.0218654, precision = 0.0, prediction/mean = 0.021423234, recall = 0.0\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 4000: /tmp/pcvr_model/model.ckpt-4000\n",
      "\n",
      "Test Accuracy: 0.990875\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:320: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:321: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/pcvr_model/model.ckpt-4000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import urllib\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "\n",
    "# Dataset should look like this \n",
    "training_set_data = np.array([[6.4, 2.8, 5.6, 2.2],\n",
    "                            [5.,  2.3, 3.3, 1. ],\n",
    "                            [4.9, 2.5, 4.5, 1.7],\n",
    "                            [4.9, 3.1, 1.5, 0.1],\n",
    "                            [5.7, 3.8, 1.7, 0.3],\n",
    "                            [4.4, 3.2, 1.3, 0.2],\n",
    "                            [5.4, 3.4, 1.5, 0.4],\n",
    "                            [6.9, 3.1, 5.1, 2.3],\n",
    "                            [6.7, 3.1, 4.4, 1.4],\n",
    "                            [5.1, 3.7, 1.5, 0.4]])\n",
    "training_set_target = np.array([2, 1, 2, 0, 0, 0, 0, 2, 1, 0])\n",
    "\n",
    "print('# training_set_data')\n",
    "print(np.array(training_set_data)[:10])\n",
    "print('# training_set_target')\n",
    "print(np.array(training_set_target)[:10])\n",
    "\n",
    "test_set_data = np.array([[5.9, 3.,  4.2, 1.5],\n",
    "                        [6.9, 3.1, 5.4, 2.1],\n",
    "                        [5.1, 3.3, 1.7, 0.5],\n",
    "                        [6.,  3.4, 4.5, 1.6],\n",
    "                        [5.5, 2.5, 4.,  1.3],\n",
    "                        [6.2, 2.9, 4.3, 1.3],\n",
    "                        [5.5, 4.2, 1.4, 0.2],\n",
    "                        [6.3, 2.8, 5.1, 1.5],\n",
    "                        [5.6, 3.,  4.1, 1.3],\n",
    "                        [6.7, 2.5, 5.8, 1.8]])\n",
    "test_set_target = np.array([1, 2, 0, 1, 1, 1, 0, 2, 1, 2])  \n",
    "print('# test_set_data')\n",
    "print(np.array(test_set_data)[:10])\n",
    "print('# test_set_target')\n",
    "print(np.array(test_set_target)[:10])\n",
    "\n",
    "today = datetime.date.today().strftime(\"%Y%m%d\")\n",
    "# calibration begin date => 12 months ago\n",
    "begin_date = '20160801'\n",
    "# obserbation end date => 3 days ago\n",
    "end_date = '20170801'\n",
    "# calibration end date => 6 months ago\n",
    "# calibration_end_date = (datetime.date.today() + relativedelta(months=-6)).strftime(\"%Y%m%d\")\n",
    "calibration_end_date = '20170201'\n",
    "# Animals In Space table\n",
    "# gap_table = 'google.com:bigquery-150208.90624960.ga_sessions_*'\n",
    "# Googel Store demo table\n",
    "gap_table = 'bigquery-public-data.google_analytics_sample.ga_sessions_*'\n",
    "\n",
    "\n",
    "print('# today: {}'.format(today))\n",
    "print('# begin_date: {}'.format(begin_date))\n",
    "print('# end_date: {}'.format(end_date))\n",
    "print('# calibration_end_date: {}'.format(calibration_end_date))\n",
    "# query to retrieve GAP exported BigQuery ecommerce tranactions (users with purchases in the calibration period)\n",
    "sql_train = \"\"\" \n",
    "          WITH ga_raw AS ( -- hit level data\n",
    "          SELECT\n",
    "            date,\n",
    "            fullVisitorId,\n",
    "            channelGrouping,\n",
    "            socialEngagementType,\n",
    "            visitId,\n",
    "            visitNumber,\n",
    "            trafficSource.source,\n",
    "            trafficSource.medium,\n",
    "            device.deviceCategory,\n",
    "            device.browser,\n",
    "            hits.hitNumber,\n",
    "            hits.page.pagePath as pagePath,\n",
    "            hits.type as type,\n",
    "            hits.eventInfo.eventCategory as eventCategory,\n",
    "            hits.eventInfo.eventAction as eventAction,\n",
    "            hits.eventInfo.eventLabel as eventLabel,\n",
    "            TIMESTAMP_SECONDS(visitStartTime) AS sessionStartTtime, \n",
    "            TIMESTAMP_ADD(TIMESTAMP_SECONDS(visitStartTime), INTERVAL hits.time MILLISECOND) AS hitTime,\n",
    "            CASE WHEN hits.hour IN (5,6,7,8,9,10) THEN 1 ELSE 0 END AS morningVisit,\n",
    "            CASE WHEN hits.hour IN (11,12,13,14,15,16) THEN 1 ELSE 0 END AS dayVisit,\n",
    "            CASE WHEN hits.hour IN (17,18,19,20,21,22) THEN 1 ELSE 0 END AS eveningVisit,\n",
    "            totals.timeOnSite AS timeOnSite,\n",
    "            totals.bounces AS bounceNumber,\n",
    "            totals.timeOnScreen\tAS timeOnScreen,\n",
    "            totals.transactions AS transactions,\n",
    "            IF(REGEXP_CONTAINS(trafficSource.source , 'google') AND REGEXP_CONTAINS(trafficSource.medium , 'cpc'), 1, 0) AS fromPaidSearch,\n",
    "            IF(REGEXP_CONTAINS(trafficSource.source , 'google') AND REGEXP_CONTAINS(trafficSource.medium , 'organic'), 1, 0) AS fromOrganicSearch\n",
    "          FROM `\"\"\"+gap_table+\"\"\"`, unnest(hits) as hits\n",
    "          WHERE\n",
    "           (_TABLE_SUFFIX >= '\"\"\"+begin_date+\"\"\"' AND _TABLE_SUFFIX <= '\"\"\"+calibration_end_date+\"\"\"') ),\n",
    "       \n",
    "        session AS ( -- aggregate hit level to session level\n",
    "          SELECT fullVisitorId, visitId,\n",
    "            SUM(if (timeOnSite is null, 0, timeOnSite)) AS timeOnSite,\n",
    "            SUM(if (bounceNumber is null, 0, bounceNumber)) AS bounceNumber,\n",
    "            SUM( dayVisit ) AS dayVisit,\n",
    "            SUM( eveningVisit ) AS eveningVisit ,\n",
    "            SUM( morningVisit ) AS morningVisit ,\n",
    "            ANY_VALUE(visitNumber) as visitNumber,\n",
    "\n",
    "            SUM(if( type = 'PAGE', 1, 0)) as totalPageViews, \n",
    "            SUM(if( type = 'EVENT', 1, 0)) as totalEvents, \n",
    "\n",
    "            SUM(if(pagePath LIKE '%/apparel%', 1, 0)) as apparelViews,\n",
    "            SUM(if(pagePath LIKE '%/bags%', 1, 0)) as bagsViews,\n",
    "            SUM(if(pagePath LIKE '%/drinkware%', 1, 0)) as drinkwareViews,\n",
    "            SUM(if(pagePath LIKE '%/accessories%', 1, 0)) as accessoriesViews,\n",
    "            SUM(if(pagePath LIKE '%/office%', 1, 0)) as officeViews,\n",
    "\n",
    "            IF(SUM(fromPaidSearch) != 0, 1, 0) AS  fromPaidSearch,\n",
    "            IF(SUM(fromOrganicSearch) != 0, 1, 0) AS  fromOrganicSearch,\n",
    "\n",
    "            IF(SUM(transactions) is null, False, True) AS hasConverted,\n",
    "\n",
    "            COUNT(*) as totalInteractions    \n",
    "          FROM ga_raw\n",
    "          GROUP BY fullVisitorId , visitId ),\n",
    "  \n",
    "       ml_dataset AS ( -- aggregate seesion level data to user level\n",
    "\n",
    "          SELECT \n",
    "            fullVisitorId, \n",
    "            MAX(visitNumber) as totalSessions,\n",
    "            SUM(totalPageViews) as totalPageViews, \n",
    "            SUM(totalInteractions) as totalInteractions, \n",
    "\n",
    "            SUM(timeOnSite) AS timeOnSite,\n",
    "            SUM(bounceNumber) AS bounceNumber,\n",
    "            SUM( dayVisit ) AS dayVisit,\n",
    "            SUM( eveningVisit ) AS eveningVisit ,\n",
    "            SUM( morningVisit ) AS morningVisit ,\n",
    "\n",
    "            SUM(totalEvents) as totalEvents, \n",
    "\n",
    "            SUM(apparelViews) as apparelViews,\n",
    "            SUM(bagsViews) as bagsViews,\n",
    "            SUM(drinkwareViews)  as drinkwareViews,\n",
    "            SUM(accessoriesViews) as accessoriesViews,\n",
    "            SUM(officeViews) as officeViews,\n",
    "\n",
    "            SUM(fromPaidSearch) AS fromPaidSearch,\n",
    "            SUM(fromOrganicSearch) AS fromOrganicSearch,\n",
    "            ANY_VALUE(hasConverted) AS hasConverted\n",
    "\n",
    "          FROM session\n",
    "          GROUP BY fullVisitorId)\n",
    "\n",
    "        select * from ml_dataset; \n",
    "\"\"\"\n",
    "\n",
    "print ('# BigQuery SQL - train data')  \n",
    "print (sql_train)\n",
    "    \n",
    "sql_test = \"\"\" \n",
    "         WITH ga_raw AS (\n",
    "          SELECT\n",
    "            date,\n",
    "            fullVisitorId,\n",
    "            channelGrouping,\n",
    "            socialEngagementType,\n",
    "            visitId,\n",
    "            visitNumber,\n",
    "            trafficSource.source,\n",
    "            trafficSource.medium,\n",
    "            device.deviceCategory,\n",
    "            device.browser,\n",
    "            hits.hitNumber,\n",
    "            hits.page.pagePath as pagePath,\n",
    "            hits.type as type,\n",
    "            hits.eventInfo.eventCategory as eventCategory,\n",
    "            hits.eventInfo.eventAction as eventAction,\n",
    "            hits.eventInfo.eventLabel as eventLabel,\n",
    "            TIMESTAMP_SECONDS(visitStartTime) AS sessionStartTtime, \n",
    "            TIMESTAMP_ADD(TIMESTAMP_SECONDS(visitStartTime), INTERVAL hits.time MILLISECOND) AS hitTime,\n",
    "            CASE WHEN hits.hour IN (5,6,7,8,9,10) THEN 1 ELSE 0 END AS morningVisit,\n",
    "            CASE WHEN hits.hour IN (11,12,13,14,15,16) THEN 1 ELSE 0 END AS dayVisit,\n",
    "            CASE WHEN hits.hour IN (17,18,19,20,21,22) THEN 1 ELSE 0 END AS eveningVisit,\n",
    "            totals.timeOnSite AS timeOnSite,\n",
    "            totals.bounces AS bounceNumber,\n",
    "            totals.timeOnScreen\tAS timeOnScreen,\n",
    "            totals.transactions AS transactions,\n",
    "            IF(REGEXP_CONTAINS(trafficSource.source , 'google') AND REGEXP_CONTAINS(trafficSource.medium , 'cpc'), 1, 0) AS fromPaidSearch,\n",
    "            IF(REGEXP_CONTAINS(trafficSource.source , 'google') AND REGEXP_CONTAINS(trafficSource.medium , 'organic'), 1, 0) AS fromOrganicSearch\n",
    "          FROM `\"\"\"+gap_table+\"\"\"`, unnest(hits) as hits\n",
    "          WHERE\n",
    "           (_TABLE_SUFFIX > '\"\"\"+calibration_end_date+\"\"\"' AND _TABLE_SUFFIX <= '\"\"\"+end_date+\"\"\"') ),\n",
    "       \n",
    "        session AS ( -- aggregate hit level to session level\n",
    "          SELECT fullVisitorId, visitId,\n",
    "            SUM(if (timeOnSite is null, 0, timeOnSite)) AS timeOnSite,\n",
    "            SUM(if (bounceNumber is null, 0, bounceNumber)) AS bounceNumber,\n",
    "            SUM( dayVisit ) AS dayVisit,\n",
    "            SUM( eveningVisit ) AS eveningVisit ,\n",
    "            SUM( morningVisit ) AS morningVisit ,\n",
    "            ANY_VALUE(visitNumber) as visitNumber,\n",
    "\n",
    "            SUM(if( type = 'PAGE', 1, 0)) as totalPageViews, \n",
    "            SUM(if( type = 'EVENT', 1, 0)) as totalEvents, \n",
    "\n",
    "            SUM(if(pagePath LIKE '%/apparel%', 1, 0)) as apparelViews,\n",
    "            SUM(if(pagePath LIKE '%/bags%', 1, 0)) as bagsViews,\n",
    "            SUM(if(pagePath LIKE '%/drinkware%', 1, 0)) as drinkwareViews,\n",
    "            SUM(if(pagePath LIKE '%/accessories%', 1, 0)) as accessoriesViews,\n",
    "            SUM(if(pagePath LIKE '%/office%', 1, 0)) as officeViews,\n",
    "\n",
    "            IF(SUM(fromPaidSearch) != 0, 1, 0) AS  fromPaidSearch,\n",
    "            IF(SUM(fromOrganicSearch) != 0, 1, 0) AS  fromOrganicSearch,\n",
    "\n",
    "            IF(SUM(transactions) is null, False, True) AS hasConverted,\n",
    "\n",
    "            COUNT(*) as totalInteractions    \n",
    "          FROM ga_raw\n",
    "          GROUP BY fullVisitorId , visitId ),\n",
    "  \n",
    "       ml_dataset AS ( -- aggregate seesion level data to user level\n",
    "\n",
    "          SELECT \n",
    "            fullVisitorId, \n",
    "            MAX(visitNumber) as totalSessions,\n",
    "            SUM(totalPageViews) as totalPageViews, \n",
    "            SUM(totalInteractions) as totalInteractions, \n",
    "\n",
    "            SUM(timeOnSite) AS timeOnSite,\n",
    "            SUM(bounceNumber) AS bounceNumber,\n",
    "            SUM( dayVisit ) AS dayVisit,\n",
    "            SUM( eveningVisit ) AS eveningVisit ,\n",
    "            SUM( morningVisit ) AS morningVisit ,\n",
    "\n",
    "            SUM(totalEvents) as totalEvents, \n",
    "\n",
    "            SUM(apparelViews) as apparelViews,\n",
    "            SUM(bagsViews) as bagsViews,\n",
    "            SUM(drinkwareViews)  as drinkwareViews,\n",
    "            SUM(accessoriesViews) as accessoriesViews,\n",
    "            SUM(officeViews) as officeViews,\n",
    "\n",
    "            SUM(fromPaidSearch) AS fromPaidSearch,\n",
    "            SUM(fromOrganicSearch) AS fromOrganicSearch,\n",
    "            ANY_VALUE(hasConverted) AS hasConverted\n",
    "\n",
    "          FROM session\n",
    "          GROUP BY fullVisitorId)\n",
    "\n",
    "        select * from ml_dataset; \n",
    "\"\"\"\n",
    "\n",
    "print ('# BigQuery SQL - test data')  \n",
    "print (sql_test)\n",
    "    \n",
    "# execute the query using datalab lib\n",
    "import google.datalab.bigquery as bq\n",
    "# Pandas lib to handle table data\n",
    "import pandas as pd\n",
    "transaction_query = bq.Query(sql_train)\n",
    "query_result = transaction_query.execute()\n",
    "query_data = query_result.result().to_dataframe()\n",
    "    \n",
    "print('# query_data # of converted users {}'.format(query_data[query_data['hasConverted']==True].shape[0]))\n",
    "print(query_data[query_data['hasConverted']==True].head(20))\n",
    "print('# query_data # of not converted users {}'.format(query_data[query_data['hasConverted']==False].shape[0]))\n",
    "print(query_data[query_data['hasConverted']==False].head(20))\n",
    "    \n",
    "training_set_data = query_data.as_matrix(columns=[\"totalPageViews\", \"totalInteractions\", \"timeOnSite\",\"bounceNumber\",\"dayVisit\",\"eveningVisit\",\"morningVisit\",\"totalEvents\",\"apparelViews\",\"bagsViews\",\"drinkwareViews\",\"accessoriesViews\",\"officeViews\",\"fromPaidSearch\",\"fromOrganicSearch\"])\n",
    "training_set_target = query_data.as_matrix(columns=[\"hasConverted\"])\n",
    "    \n",
    "    \n",
    "test_transaction_query = bq.Query(sql_test)\n",
    "test_query_result = test_transaction_query.execute()\n",
    "test_query_data = test_query_result.result().to_dataframe()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fba34eee310>, '_evaluation_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_device_fn': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/tmp/pcvr_model', '_train_distribute': None, '_save_summary_steps': 100}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/pcvr_model/model.ckpt-4000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 4000 into /tmp/pcvr_model/model.ckpt.\n",
      "INFO:tensorflow:loss = 4.9095674e-05, step = 4001\n",
      "INFO:tensorflow:global_step/sec: 345.515\n",
      "INFO:tensorflow:loss = 5.3152085e-05, step = 4101 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 458.485\n",
      "INFO:tensorflow:loss = 4.761521e-05, step = 4201 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 498.219\n",
      "INFO:tensorflow:loss = 5.3210817e-05, step = 4301 (0.201 sec)\n",
      "INFO:tensorflow:global_step/sec: 489.805\n",
      "INFO:tensorflow:loss = 5.4458753e-05, step = 4401 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 409.981\n",
      "INFO:tensorflow:loss = 5.247357e-05, step = 4501 (0.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 462.856\n",
      "INFO:tensorflow:loss = 5.5999557e-05, step = 4601 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 466.71\n",
      "INFO:tensorflow:loss = 5.2465413e-05, step = 4701 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 409.286\n",
      "INFO:tensorflow:loss = 0.98675495, step = 4801 (0.244 sec)\n",
      "INFO:tensorflow:global_step/sec: 442.419\n",
      "INFO:tensorflow:loss = 0.054182336, step = 4901 (0.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 425.499\n",
      "INFO:tensorflow:loss = 0.0032334486, step = 5001 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 446.23\n",
      "INFO:tensorflow:loss = 0.0026798684, step = 5101 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 448.085\n",
      "INFO:tensorflow:loss = 0.0016353925, step = 5201 (0.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.779\n",
      "INFO:tensorflow:loss = 0.001432615, step = 5301 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 428.093\n",
      "INFO:tensorflow:loss = 0.0003791341, step = 5401 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 448.425\n",
      "INFO:tensorflow:loss = 0.00019953545, step = 5501 (0.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.359\n",
      "INFO:tensorflow:loss = 0.00042890175, step = 5601 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 466.596\n",
      "INFO:tensorflow:loss = 0.9641396, step = 5701 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 442.641\n",
      "INFO:tensorflow:loss = 21.28358, step = 5801 (0.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 417.92\n",
      "INFO:tensorflow:loss = 0.8492433, step = 5901 (0.239 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6000 into /tmp/pcvr_model/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 1.1220421e-06.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-08-02-17:08:40\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/pcvr_model/model.ckpt-6000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-08-02-17:08:48\n",
      "INFO:tensorflow:Saving dict for global step 6000: accuracy = 0.99024713, accuracy_baseline = 0.9908754, auc = 0.95159525, auc_precision_recall = 0.1474957, average_loss = 0.04330552, global_step = 6000, label/mean = 0.009124599, loss = 5.5421877, precision = 0.20597015, prediction/mean = 0.024892194, recall = 0.024117442\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 6000: /tmp/pcvr_model/model.ckpt-6000\n",
      "\n",
      "Test Accuracy: 0.990247\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:39: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:40: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/pcvr_model/model.ckpt-6000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "test_set_data = test_query_data.as_matrix(columns=[\"totalPageViews\", \"totalInteractions\", \"timeOnSite\",\"bounceNumber\",\"dayVisit\",\"eveningVisit\",\"morningVisit\",\"totalEvents\",\"apparelViews\",\"bagsViews\",\"drinkwareViews\",\"accessoriesViews\",\"officeViews\",\"fromPaidSearch\",\"fromOrganicSearch\"])\n",
    "test_set_target = test_query_data.as_matrix(columns=[\"hasConverted\"])\n",
    "    \n",
    "# Specify that all features have real-value data\n",
    "feature_columns = [tf.feature_column.numeric_column(\"x\", shape=[15])]\n",
    "\n",
    "# Build 3 layer DNN with 10, 20, 10 units respectively.\n",
    "classifier = tf.estimator.DNNClassifier(feature_columns=feature_columns,\n",
    "                                        hidden_units=[10, 20, 10],\n",
    "                                        n_classes=2,\n",
    "                                        model_dir=\"/tmp/pcvr_model\")\n",
    "# Define the training inputs\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": np.array(training_set_data)},\n",
    "    y=np.array(training_set_target),\n",
    "    num_epochs=None,\n",
    "    shuffle=True)\n",
    "\n",
    "# Train model.\n",
    "classifier.train(input_fn=train_input_fn, steps=2000)\n",
    "\n",
    "# Define the test inputs\n",
    "test_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": np.array(test_set_data)},\n",
    "    y=np.array(test_set_target),\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "\n",
    "# Evaluate accuracy.\n",
    "accuracy_score = classifier.evaluate(input_fn=test_input_fn)[\"accuracy\"]\n",
    "\n",
    "print(\"\\nTest Accuracy: {0:f}\\n\".format(accuracy_score))\n",
    "\n",
    "# Classify samples.\n",
    "new_input = np.array(\n",
    "    [[6.4, 3.2, 4.5, 1.5],\n",
    "    [5.8, 3.1, 5.0, 1.7]], dtype=np.float32)\n",
    "new_input= test_query_data[query_data['hasConverted']==False].as_matrix(columns=[\"totalPageViews\", \"totalInteractions\", \"timeOnSite\",\"bounceNumber\",\"dayVisit\",\"eveningVisit\",\"morningVisit\",\"totalEvents\",\"apparelViews\",\"bagsViews\",\"drinkwareViews\",\"accessoriesViews\",\"officeViews\",\"fromPaidSearch\",\"fromOrganicSearch\"])\n",
    "new_input_key = test_query_data[query_data['hasConverted']==False].as_matrix(columns=[\"fullVisitorId\"])\n",
    "predict_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": new_input},\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "\n",
    "predictions = list(classifier.predict(input_fn=predict_input_fn))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "fullVisitorId: 5900472703847352092\n",
      "\n",
      "fullVisitorId: 0424668908545837304\n",
      "\n",
      "fullVisitorId: 5484016666945224510\n",
      "\n",
      "fullVisitorId: 6719182032425610749\n",
      "\n",
      "fullVisitorId: 6343719132544553875\n",
      "{'probabilities': array([1.00000000e+00, 1.15154375e-08], dtype=float32), 'logits': array([-18.279577], dtype=float32), 'classes': array(['0'], dtype=object), 'class_ids': array([0]), 'logistic': array([1.1515438e-08], dtype=float32)}\n",
      "[1.00000000e+00 1.15154375e-08]\n",
      "1.15154375e-08\n",
      "{'probabilities': array([1.00000000e+00, 1.15154375e-08], dtype=float32), 'logits': array([-18.279577], dtype=float32), 'classes': array(['0'], dtype=object), 'class_ids': array([0]), 'logistic': array([1.1515438e-08], dtype=float32)}\n",
      "[1.00000000e+00 1.15154375e-08]\n",
      "1.15154375e-08\n",
      "{'probabilities': array([1.00000000e+00, 1.15154375e-08], dtype=float32), 'logits': array([-18.279577], dtype=float32), 'classes': array(['0'], dtype=object), 'class_ids': array([0]), 'logistic': array([1.1515438e-08], dtype=float32)}\n",
      "[1.00000000e+00 1.15154375e-08]\n",
      "1.15154375e-08\n",
      "{'probabilities': array([9.999999e-01, 9.977025e-08], dtype=float32), 'logits': array([-16.120396], dtype=float32), 'classes': array(['0'], dtype=object), 'class_ids': array([0]), 'logistic': array([9.977026e-08], dtype=float32)}\n",
      "[9.999999e-01 9.977025e-08]\n",
      "9.977025e-08\n",
      "{'probabilities': array([1.00000000e+00, 1.15154375e-08], dtype=float32), 'logits': array([-18.279577], dtype=float32), 'classes': array(['0'], dtype=object), 'class_ids': array([0]), 'logistic': array([1.1515438e-08], dtype=float32)}\n",
      "[1.00000000e+00 1.15154375e-08]\n",
      "1.15154375e-08\n",
      "\n",
      "fullVisitorId: 5900472703847352092, probability: 0.0\n",
      "\n",
      "fullVisitorId: 0424668908545837304, probability: 0.0\n",
      "\n",
      "fullVisitorId: 5484016666945224510, probability: 0.0\n",
      "\n",
      "fullVisitorId: 6719182032425610749, probability: 0.0\n",
      "\n",
      "fullVisitorId: 6343719132544553875, probability: 0.0\n",
      "(311959, 1)\n",
      "(311959, 1)\n",
      "         fullVisitorId  probability\n",
      "0  5900472703847352092  1.15154e-06\n",
      "1  0424668908545837304  1.15154e-06\n",
      "2  5484016666945224510  1.15154e-06\n",
      "3  6719182032425610749  9.97702e-06\n",
      "4  6343719132544553875  1.15154e-06\n"
     ]
    }
   ],
   "source": [
    "for key in new_input_key[:5,:]:\n",
    "  fullVisitorId = key[0]\n",
    "  print(\"\\nfullVisitorId: {}\".format(fullVisitorId))\n",
    "\n",
    "for p in predictions[:5]:\n",
    "  print (p)\n",
    "  pred = p['probabilities']\n",
    "  print(pred)\n",
    "  prob = p['probabilities'][1]\n",
    "  print(prob)\n",
    "p_array = np.empty((0, 1))\n",
    "for prob in predictions:\n",
    "  probability = prob['probabilities'][1]*100\n",
    "  new_row = np.array([[probability]])\n",
    "  p_array = np.vstack((p_array, new_row))\n",
    "  \n",
    "for key, prob in zip(new_input_key[:5,:], predictions[:5]):\n",
    "    probability = prob['probabilities'][1] # probabilty of conversion (class id = 1)\n",
    "    fullVisitorId = key[0]\n",
    "    print(\"\\nfullVisitorId: {}, probability: {:.1f}\".format(fullVisitorId,\n",
    "                          100 * probability))\n",
    "#p = np.array(prob['probabilities'][1] for prob in predictions)\n",
    "print(p_array.shape)\n",
    "print(new_input_key.shape)\n",
    "df = pd.DataFrame(np.hstack((new_input_key, p_array)), columns=['fullVisitorId','probability'])\n",
    "#df = pd.DataFrame(np.hstack((new_input_key, predictions(['probabilities'][1]))), columns=['fullVisitorId','probability'])\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
